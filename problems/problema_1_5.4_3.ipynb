{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1 sección 5.4 ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now review k-fold cross-validation.\n",
    "\n",
    "\n",
    "(a) Explain how k-fold cross-validation is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada (cross-validation) en k-folds se implementa con los siguientes pasos:\n",
    "\n",
    "1. Se particiona aleatoriamente el conjunto de datos en `k` subconjuntos.\n",
    "\n",
    "2. Se utilizan $k-1$ sunconjuntos para entrenar el modelo y el conjunto restante se utiliza para evaluarlo. Este proceso se repite $k$ veces, de tal forma que cada subconjunto se utiliza una vez para evaluar el modelo.\n",
    "\n",
    "3. Se obtiene el promedio del error en las evaluaciones realizadas para obtener la estimación del error general del modelo. Es decir, se calcula al final una métrica de error ponderada. Por ejemplo, si estamos utilizando el $MSE$ como métrica de error, la estimación del error general del modelo sería:\n",
    "\n",
    "$$ CV_k = \\frac{1}{k} \\sum_{i=1}^{n} MSE_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What are the advantages and disadvantages of k-fold cross-validation relative to:\n",
    "\n",
    "Es importante recordar, que en el método ***k-fold cross validation*** existe un trafe-off entre sesgo y varianza según el valor que se elija de `k`. \n",
    "\n",
    "Entre mayor sea el valor de `k`, la partición de los datos se asemeja cada vez más al método ***LOOCV***, en el cual, una mayor proporción de los datos son incluidos en el conjunto de entrenamiento y, por lo tanto, el sesgo respecto a la estimación del error al utilizar todos los datos tiende a disminuir, mientras que la varianza y la flexibilidad de la estimación tienden a aumentar.\n",
    "\n",
    "Por otra parte, entre menor sea el valor de `k`, la partición de los datos se asemeja cada vez más al enfoque de ***Validation set***, por lo que aumenta el sesgo respecto a la estimación del error cuando se usan todos los datos, pero disminuye la varianza y la flexibilidad de la estimación.\n",
    "\n",
    "En clonclusión, las ventajas y desventajas respecto a otro métodos, dependen del valor de `k`. Sin embargo, si asumimos un `k` igual a 5 o a 10, este método permite estimaciones sin un sesgo excesivamente grande ni de varianza muy alta. Por lo que vamos a asumir que el método usa un `k`= 5 para describir las ventajas y las desventajas respecto a los otros métodos.\n",
    "\n",
    "\n",
    "i. The ***validation set approach***?\n",
    "\n",
    "* **Ventajas**:\n",
    "  * En el enfoque de ***validation set***, cuando se repite el proceso varias veces, el error estimado tiende a variar mucho, dada la partición aleatoria de los datos en cada repetición. \n",
    "  Cuando se utiliza ***k-folds cross validation*** la variabilidad del error estimado disminuye considerablemente, porque no existen solo dos formas muy diferentes de separar los datos, sino k (5) formas (no tan diferentes entre sí) de hacerlo.\n",
    "\n",
    "  * Si comparamos el error encontrado al entrenar el modelo con todos los datos, con el error encontrado con los enfoques de ***k-folds cross validation*** y de ***validation set***. Se tiene que en el método de ***k-folds cross validation***, hay un menor sesgo porque se utiliza una mayor cantidad de datos en el conjunto de entrenamiento, por lo que su estimación se acerca más a la estimación con todo el conjunto de datos.  \n",
    "\n",
    "\n",
    "* **Desventajas**:\n",
    "  * Se tiene que realizar el entrenamiento $k$ veces, lo que puede ser más costoso computacionalmente cuando `k`>2. \n",
    "  * Adicionalmente, tiene una mayor varianza que ***validation set***. Lo que en algunos casos podría ser algo negativo.\n",
    "\n",
    "  Sin embargo, para un `k`=5, estas dos desventajas no representan problemas mayores.\n",
    "\n",
    "ii. **Leave-One-Out Cross Validation (LOOCV)**?\n",
    "\n",
    "  En general, las ventajas y deventajas, dependen del valor de `k`.\n",
    "\n",
    "* **Ventajas**:\n",
    "  * Para un `k`<`n` es menos costoso computacionalmente que ***LOOCV***.\n",
    "  * A menudo da estimaciones más precisas de la tasa de error que ***LOOCV***, esto se debe al trade-off entre varianza y sesgo que hacen que dichas estimaciones no estén *sobreajustadas*.\n",
    "\n",
    "\n",
    "* \n",
    "* **Desventajas**:\n",
    "  * Si no se elige el valor de `k` adecuado, este método podría tener un sesgo alto que no sea compensado por su baja varianza, o viceversa. Para un `k`=5, esto no representa un problema significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
